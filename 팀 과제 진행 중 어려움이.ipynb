{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# RuntimeError: stack expects each tensor to be equal size, but got [43] at entry 0 and [30] at entry 1\n",
    "# 이 에러는 DataLoader가 배치를 만들 때 각 샘플의 길이가 달라서 발생했다.\n",
    "# LSTM 모델에 입력할 데이터는 일정한 길이의 시퀀스로 맞춰줘야 한다. 따라서 리뷰 텍스트의 길이를 맞추기 위해 패딩(padding)을 적용하는 방법이 필요하다.\n",
    "\n",
    "# 즉, 길이가 서로 다른 리뷰를 동일한 길이로 맞춰주는 함수(=> collate_fn)를 정의하여 DataLoader에 전달해야 한다.\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 패딩 적용 함수\n",
    "def collate_fn(batch):\n",
    "    reviews, ratings = zip(*batch)\n",
    "    reviews_padded = pad_sequence(reviews, batch_first=True, padding_value=0)  # 0으로 패딩\n",
    "    ratings = torch.tensor(ratings)  # 텐서로 변환\n",
    "    return reviews_padded, ratings\n",
    "\n",
    "# 데이터 로더 정의 시 collate_fn 전달\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "# ValueError: Expected input batch_size (1) to match target batch_size (64).\n",
    "# 이 오류는 outputs의 배치 크기와 y_batch의 배치 크기가 일치하지 않아서 발생한다. outputs와 y_batch 모두 64개의 배치 크기를 가져야 한다.\n",
    "# 지금 모델의 forward 메서드에서 embedded.unsqueeze(0)을 사용해 배치 크기를 1로 만들고 있다.\n",
    "# 이를 해결하려면 forward 메서드에서 배치 크기 전체를 처리할 수 있도록 unsqueeze(0)을 제거야 한다.\n",
    "# 또는, nn.EmbeddingBag 대신 nn.Embedding을 사용할 수도 있다.\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)    # (batch_size, seq_length, embed_dim)\n",
    "        output, (hidden, cell) = self.lstm(embedded)   # 원래 self.lstm(embedded.unsqueeze(0))였는데, unsqueeze(0)을 제거했다.   # output: (batch_size, seq_length, hidden_dim)\n",
    "        # hidden의 마지막 상태를 사용하여 출력을 만든다.\n",
    "        return self.fc(hidden[-1])# hidden[-1]은 (1, batch_size, hidden_dim) 형태이므로, squeeze 필요\n",
    "\n",
    "# RuntimeError: size mismatch (got input: [5], target: [64])\n",
    "# 이번 오류는 모델의 출력 차원과 타겟(y_batch)의 차원이 맞지 않아서 발생했다.\n",
    "# 주의해야 할 점은 outputs의 형상이 (batch_size, output_dim)이어야 하며, y_batch는 크기가 (batch_size,)인 텐서여야 한다는 것이다.\n",
    "# 현재 오류 메시지에서 outputs의 크기가 [5]이고 y_batch의 크기가 [64]라는 것은, 모델이 배치의 모든 데이터에 대해 올바른 출력을 내지 못하고 있다는 것을 의미한다.\n",
    "# 여기서 몇 가지 사항을 확인하고 수정해야 한다.\n",
    "# 모델 출력 차원: output_dim이 올바르게 설정되었는지 확인하세요. 보통 감정 분류 문제에서는 클래스의 수와 같아야 합니다.\n",
    "# 데이터 준비: 데이터 로더에서 배치 크기를 확인하고, y_batch가 올바른 형태로 준비되었는지 점검하세요.\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "# 학습 루프에서 y 대신 y_batch 사용\n",
    "# y 사용 시 에러 발생 : TypeError: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not list\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        outputs = model(X_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, y_batch)   # y_batch를 사용하여 텐서 형태 보장. 이렇게 하면 CrossEntropyLoss에 전달되는 target이 올바르게 텐서로 인식되어 에러가 해결된다.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
