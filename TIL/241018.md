## **비지도학습**

**지도학습**은 정답이 존재하고, 이 정답을 맞추거나 예측하는 문제를 푸는데, 데이터에도 정답이 포함돼있어야 했다. 이에 반해 **비지도학습**은 정답을 맞추는 문제를 풀지 않는다. 비지도학습 중 군집화모델에 대해 알아보자. 먼저 군집화모델 중 k-means clusterig을 먼저 살펴보자.

### **1\. 군집화모델**

####      **1) k-means clustering**

이는 데이터를 그림으로 표현했을 때 가까운 애들끼리 묶는 것을 말한다. 머신러닝보다 **알고리즘**에 더 가깝다고 한다. 군집을 몇 개로 설정할 지를 구하는 방법으로 엘보우 방법이 있다. **엘보우 방법**은 군집이 뭉쳐있을 수록 군집화가 잘 된 것인데, 이렇게 되게 하는 개수를 선택하는 방법이다.

####      **2) 계층적 군집화**

데이터포인트를 계층 구조로 그룹화하는 방법이다. 크게 병합 군집화와 분할 군집화로 나뉜다. **병합 군집화**는 m개의 군집이 있다고 할 때, 가장 가까운 군집과 병합해나감으로써 점차적으로 1개의 군집이 되는 군집화다. **분할 군집화**는 이와 반대로 1개의 군집에서, 가장 멀리 떨어진 데이터를 분할함으로써, 최종적으로 m개의 군집이 되는 군집화다. 병합 군집화보다 분할 군집화가 더 효율적이나, 구현은 더 복잡하다.

####      **3)** **DBSCAN**

밀도 기반 군집화 알고리즘으로, 데이터 밀도가 높은 영역을 군집으로 간주하고, 밀도가 낮은 영역은 노이즈로 처리한다. 거리 기반과 달리 밀도 기반으로 하면 비원형 cluster도 찾을 수 있다.

---

### **2\. 차원축소**

####      **1) PCA**

고차원 데이터를 저차원으로 변환하는 차원 축소 기법이다. 데이터의 분산을 최대한 보존하면서, 데이터의 주요 특징을 추출해 저차원 공간으로 변환한다. 데이터의 시각화, 노이즈 제거, 계산 효율성 향상 등의 이점을 얻을 수 있다.

PCA는 개념적으로 이해하는 게 좋은데, 통계학과 선형대수 개념이 많이 사용되기 때문이다. 더 공부하고 싶다면 PCA를 공부하기 보다 **통계학에서 분산의 개념, 상관관계의 개념과 선형대수의 벡터와 고유값**을 공부하는 것을 추천한다.

####     **2)** **t-SNE**

고차원 데이터를 저차원으로 변환하여 시각화하는 차원 축소 기법으로, 데이터 포인트 간의 유사성을 보존하면서, 고차원 데이터를 2차원 또는 3차원 공간으로 변환한다. 이를 통해 데이터의 구조와 패턴을 시각적으로 이해할 수 있다.

우리는 **고차원 데이터 포인터 간의 유사성을 저차원에서도 유지하도록 차원을 축소한다**는 것만 알고 가자.

####     **3)** **LDA**

차원 축소와 분류를 동시에 수행한다. 데이터의 분류 성능을 향상시키고, 저차원 공간에서 데이터의 구조를 시각화할 수 있다.

여기서는 **클래스 내 분산은 최소로, 클래스 간에는 최대로 하는 변환 행렬을 찾는 방법이 통계학과 선형대수에 있기 때문에, 이를 사용해서 데이터를 변환한다**는 점을 이해하면 된다.

---

####    **강의 외부에서 추가로 알게 된 내용**

-   **리스트 내포( list comprehension )**

**\- \[expression for item in iterable if condition\]**

1.  **iterable**: 리스트, 문자열, 튜플 등 반복 가능한 객체. for item in iterable 부분은 반복문처럼 **iterable의 각 요소**를 item에 하나씩 할당하는 과정이다.
2.  **expression**: 각 item에 대해 수행되는 **연산 또는 변환**. 이 연산이 수행된 값이 최종적으로 **새로운 리스트에 추가**된다. 즉, expression을 적용한 결과가 새로운 리스트의 요소로 들어가는 것.
3.  **if condition**: if는 **선택적**. 만약 if condition이 있으면, 그 조건을 만족하는 item만 expression을 거친 후 **새 리스트에 추가**된다. 조건을 만족하지 않는 값은 리스트에 추가되지 않는다.

\- 리스트 내포는 **내부적으로 새로운 리스트에 값을 추가**하는 동작을 하고, 이때 **append()처럼 동작**한다고 볼 수 있다.

  하지만 단순히 append()에 국한되지 않고, **조건부 필터링**, **값 변환**, **중첩 리스트 내포** 등 더 복잡한 동작을 지원한다.

\- 리스트 내포의 주요 기능

**1\. 값 추가 (append()와 유사한 동작) :** 리스트 내포의 기본 동작은 **새로운 리스트에 값을 추가**하는 것.

```
new_list = [i for i in range(5)] # new_list = [0, 1, 2, 3, 4]
```

 이 경우는 append()처럼 각 i 값을 새로운 리스트에 추가하는 것.

**2\. 조건부 필터링 (if 사용)** **:** if 문을 사용하여 조건을 만족하는 값만 리스트에 추가할 수 있다. 이 동작은 단순한 append()와는 차이가 있다.

```
new_list = [i for i in range(5) if i % 2 == 0] # new_list = [0, 2, 4]
```

여기서는 짝수만 리스트에 추가하는 조건을 붙인 것이며, i % 2 == 0을 만족하는 값만 리스트에 들어갑니다.

**3\. 값 변환 :** 각 요소에 대해 **변환**을 수행할 수 있다.

```
new_list = [i * 2 for i in range(5)] # new_list = [0, 2, 4, 6, 8]
```

이 경우, 리스트의 각 요소에 2를 곱한 결과를 새로운 리스트에 추가한다.

**4\. 중첩된 리스트 내포** (2차원 배열 변환 등) **:** 리스트 내포는 중첩된 반복문도 지원하여 2차원 리스트나 더 복잡한 구조를 처리할 수 있다.

```
matrix = [[i * j for j in range(3)] for i in range(3)] # matrix = [[0, 0, 0], [0, 1, 2], [0, 2, 4]]
```

여기서는 두 개의 반복문을 이용해 2차원 리스트를 생성하고 있다.