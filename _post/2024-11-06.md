---
title: "[GitHub Blog] TIL 30"

writer: ysooj
categories:
- GitHub Blog
tags: [Blog, jekyll, Github, Git, markdown, TIL]

toc: true
toc_sticky: true

date: 2024-11-06
---

생성형 AI를 직접 만들 때 맞닥뜨릴 수 있는 어려움
일반적으로 생성형 AI라고 하면, 2가지 종류가 있다. 먼저, 사용자로부터 입력을 받지 않고, 임의의 생성을 해주는 모델이 있다. 그러나 이는 사용자가 원하는 생성을 할 수 없다는 특징 때문에 상대적으로 활용도가 떨어진다. 최근에는 사용자로부터 입력을 받고, 그 입력에 따라 적절한 콘텐츠를 생성해주는 걸 생성형 AI라고 많이 통칭하고 있는 것 같다.



우리가 생성형 AI를 직접 만드는 건 매우 어렵다.

why?

대규모 데이터와 컴퓨팅 자원이 필요하다. 생성형 AI는 학습하기 위한 데이터의 양이 굉장히 많은 편에 속한다. 또 생성형 AI 모델은 GPU 등 같은 고성능 하드웨어에서 오랜 시간 학습해야 한다. 즉,  데이터 수집 자체도 어려울 뿐더러, 컴퓨팅 자원의 한계가 바로 나타나게 된다.

모델 구조가 굉장히 복잡하다. 딥러닝 개념만 사용되는 게 아니고, 특정 도메인에 맞는 생성을 하기 위해서 도메인 지식(Domain Knowledge)가 반영된 코드, 강화학습 등 다른 인공지능 분류의 기법들이 많이 적용된다. 모델 아키텍처 설계 단계에서도 여러 층의 신경망과 다양한 메커니즘이 포함되고, 학습률, 배치 크기, 레이어 수 등 다양한 하이퍼파라미터를 적절히 조절해야 최적의 성능을 낼 수 있기 때문에 하이퍼파라미터 튜닝도 해야 한다.

훈련 과정에 대한 불안정성이 있다. 특정 패턴의 결과물만 만들어내거나, 혹은 학습이 되지 않는 등 다양한 문제가 발생한다. 모델 붕괴라고 하는 현상이 종종 나오게 된다. 균형 잡힌 학습, 우리는 균형잡힌 구조까지 작성해야 의미있는 생성형 모델을 만들 수 있을 것이다.

파인 튜닝의 필요
생성형 AI는 복잡성과 훈련의 어려움 때문에, Fine-Tuning을 통해 만들어내는 경우가 많다. 이미 사전에 연구가 잘 수행되고, 대규모 데이터셋에 대해 일반적 지식을 얻은 모델을 습득함으로써, 이 모델을 본인만의 목적을 위해 Fine-Tuning하는 작업을 준비할 수 있다.



사전 학습된 모델을 사용하면, 이미 방대한 데이터로 강력한 컴퓨팅 자원을 통해 충분히 안정적으로 학습이 된 형태로 모델이 제공되게 된다. 그래서 우리는 시간과 비용을 절감할 수 있다. 그리고 성능적으로도 훨씬 높은 성능을 얻을 수 있을 것이다.

생성형 AI를 직접 만들 때 고려해야 할 점
사전 학습된 모델을 먼저 찾아보자. 사전 학습된 모델을 활용해서 생성형 AI 만드는 게 더 효율적일 수 있다. 개인 컴퓨터에서 학습을 진행한다고 했을 때, 너무 오래 걸리거나 메모리적인 부분때문에 억지로 학습을 축소시켜야할 경우가 있을 수도 있다. 내가 좋은 모델을 디자인했다고 하더라도, 학습이 제대로 되지 않으면 당연히 인공지능은 원하는 결과를 얻을 수 없게 된다. 클라우드 서비스를 활용하면 좋은데, 당연히 비용적인 측면을 먼저 확인하고 진행하는 것이 좋다. 작은 프로젝트부터 시작해서, 천천히 조금씩 확장해나가면서 모델을 복잡하게 만들어나가자.





강의 외부에서 추가로 알게 된 내용
re.findall() 함수
re.fin